# Chaos Engineering Tests Implementation

## Overview

Comprehensive chaos engineering tests for parallelization system validation according to ASSUMPTIONS_AND_TESTING.md requirements (lines 694-700).

## File Location

`/mnt/c/Users/masha/Documents/claude-flow-novice/tests/parallelization/chaos.test.ts`

## Requirements Validated

### 1. Random Agent Crashes (30%)
- **Requirement:** 30% random agent crashes â†’ 100% cleanup within 3min
- **Test:** `should cleanup all crashed agents within 3 minutes`
- **Implementation:**
  - Spawns 30 agents total
  - Randomly crashes 9 agents (30%)
  - Waits for 3-minute orphan detection threshold
  - Runs OrphanDetector to cleanup crashed agents
  - Validates 100% cleanup rate
  - Verifies all crashed agent IDs are cleaned

### 2. Redis Connection Failures
- **Requirement:** Redis connection failures â†’ Recovery within 30s
- **Test:** `should recover all agents within 30 seconds of Redis reconnection`
- **Implementation:**
  - Spawns 10 agents with active heartbeats
  - Simulates Redis disconnect by stopping heartbeat intervals
  - Waits 5 seconds to simulate connection loss
  - Simulates reconnection by restarting heartbeats
  - Polls for recovery (max 30 seconds)
  - Validates all agents recover with recent heartbeats

### 3. Concurrent File Edits
- **Requirement:** Concurrent file edits â†’ 100% conflict detection
- **Test:** `should detect 100% of file conflicts from concurrent edits`
- **Implementation:**
  - Simulates 5 agents editing the same file simultaneously
  - Detects conflicts by checking if file was modified by another agent
  - Validates 100% conflict detection rate (excluding first edit)
  - Uses file system locks and timestamp checking

### 4. Test Lock Crashes
- **Requirement:** Test lock crashes â†’ Stale lock release within 15min
- **Test:** `should release stale locks within 15 minutes after agent crash`
- **Implementation:**
  - Agent acquires lock with 15-minute TTL
  - Simulates agent crash without lock release
  - Uses shortened TTL (10s) for faster testing validation
  - Validates lock expires via Redis TTL mechanism
  - Verifies new agents can acquire lock after expiration
  - Additional test validates lock exclusivity during active period

## Test Configuration

```typescript
const CHAOS_CONFIG = {
  // Test 1: Random Agent Crashes
  TOTAL_AGENTS: 30,
  CRASH_PERCENTAGE: 0.3, // 30%
  ORPHAN_CLEANUP_THRESHOLD: 3 * 60 * 1000, // 3 minutes
  HEARTBEAT_INTERVAL: 5 * 1000, // 5 seconds
  ORPHAN_CHECK_INTERVAL: 10 * 1000, // 10 seconds

  // Test 2: Redis Connection Failures
  REDIS_RECOVERY_TIMEOUT: 30 * 1000, // 30 seconds
  RECONNECT_POLL_INTERVAL: 1000, // 1 second

  // Test 3: Concurrent File Edits
  CONCURRENT_EDITORS: 5,
  EDIT_DURATION: 2000, // 2 seconds per edit

  // Test 4: Test Lock Crashes
  LOCK_TTL: 15 * 60, // 15 minutes in seconds
  STALE_LOCK_CHECK_INTERVAL: 5000, // 5 seconds
};
```

## Helper Classes

### OrphanDetector
- Detects agents with stale heartbeats (beyond threshold)
- Cleans up orphaned agent Redis keys
- Returns cleanup metrics (orphan IDs, cleanup duration)

### TestLockManager
- Manages Redis-based distributed locks
- Implements lock acquisition with TTL
- Provides lock state inspection
- Validates lock expiration

## Helper Functions

### spawnAgent(redis, agentId, enableHeartbeat)
- Creates agent state in Redis
- Starts heartbeat interval if enabled
- Returns AgentInstance object

### crashAgent(agent)
- Simulates immediate crash without cleanup
- Stops heartbeat interval
- Leaves Redis state intact (orphan)

### stopAgent(redis, agent)
- Graceful agent shutdown with cleanup
- Stops heartbeat interval
- Removes all Redis keys

### simulateConcurrentEdit(agentId, filePath, content)
- Simulates concurrent file edit
- Detects conflicts based on file state
- Returns FileEditConflict result

## Edge Cases Tested

1. **Multiple Simultaneous Crashes**
   - Crashes all 20 agents simultaneously
   - Validates orphan detector handles mass failures
   - Ensures 100% cleanup

2. **Partial Crashes**
   - Crashes 50% of agents
   - Validates healthy agents continue running
   - Ensures cleanup doesn't affect healthy agents

3. **Lock Exclusivity**
   - Validates only one agent can hold lock
   - Tests lock blocking during active period
   - Validates post-expiration acquisition

## Test Timeouts

- Test 1 (Agent Crashes): 6 minutes (3min threshold + 3min buffer)
- Test 2 (Redis Recovery): 2 minutes
- Test 3 (File Conflicts): 30 seconds
- Test 4 (Lock Expiration): 60 seconds

## Dependencies

### Required npm packages:
```json
{
  "devDependencies": {
    "vitest": "^1.0.0" // MISSING - needs to be added
  },
  "dependencies": {
    "ioredis": "^5.8.1" // Already installed
  }
}
```

### Existing helper utilities:
- `tests/chaos/utils/chaos-helpers.ts` - sleep, randomInt functions

## Installation Instructions

### 1. Install Vitest
```bash
npm install --save-dev vitest
```

### 2. Update package.json
Add vitest to devDependencies:
```json
{
  "devDependencies": {
    "vitest": "^1.0.0"
  }
}
```

### 3. Run Tests
```bash
# Run all chaos tests
npm run test:chaos

# Run specific parallelization chaos tests
vitest run tests/parallelization/chaos.test.ts --timeout 20m
```

## Test Execution

### Local Execution
```bash
# Full chaos test suite (including network tests)
npm run test:chaos:local

# Parallelization chaos tests only
vitest run tests/parallelization/chaos.test.ts
```

### CI Execution
```bash
# Excludes network partition tests (requires sudo)
npm run test:chaos:ci
```

## Expected Console Output

### Test 1: Agent Crashes
```
ğŸ§ª Spawning 30 agents, crashing 9 (30%)...
ğŸ’¥ Crashed agent: chaos-agent-0
ğŸ’¥ Crashed agent: chaos-agent-5
...
â³ Waiting 180s for orphan detection threshold...
âœ… Cleanup completed in 1234ms (detection + cleanup: 567ms)
ğŸ“Š Orphans detected: 9
ğŸ“Š Expected crashes: 9
ğŸ“Š Cleanup rate: 100.00%
```

### Test 2: Redis Recovery
```
ğŸ§ª Spawning 10 agents...
ğŸ’” Simulating Redis disconnect...
â³ Waiting 5 seconds to simulate connection loss...
ğŸ’š Simulating Redis reconnection...
â³ Waiting for recovery (max 30s)...
âœ… Recovery completed in 12345ms (12.35s)
```

### Test 3: File Conflicts
```
ğŸ§ª Simulating 5 agents editing same file concurrently...
ğŸ“„ Test file: /tmp/chaos-test-1234567890.txt
ğŸ“Š Total edits: 5
ğŸ“Š Conflicts detected: 4
ğŸ“Š Conflict detection rate: 100.00%
âœ… File conflict detection validated
```

### Test 4: Lock Expiration
```
ğŸ§ª Agent acquiring test lock...
âœ… Lock acquired by lock-holder-agent
ğŸ“Š Lock TTL: 900s (15.00 minutes)
ğŸ’¥ Simulating agent crash (without lock release)...
â³ Testing with 10s TTL for faster validation...
ğŸ“Š Lock state after 10s:
   Holder: NONE
   TTL: -2
   Expired: true
âœ… Stale lock released successfully via TTL expiration
âœ… New agent new-lock-holder successfully acquired lock after expiration
```

## Validation Criteria

All tests must pass with:
- âœ… 100% cleanup rate for crashed agents
- âœ… Recovery within 30 seconds
- âœ… 100% conflict detection
- âœ… Stale lock release within TTL

## Blockers

### Current Blocker: Missing Vitest Dependency

**Status:** vitest package not installed in project

**Resolution Required:**
```bash
npm install --save-dev vitest
```

**Alternative:** Use Jest instead (already installed) by converting test syntax:
- Change `import { describe, it, expect, beforeEach, afterEach } from 'vitest'`
- To `import { describe, it, expect, beforeEach, afterEach } from '@jest/globals'`
- Update timeout syntax from `{ timeout: 60000 }` to Jest's timeout configuration

## Test Quality Metrics

- **Total Test Cases:** 7 main tests + 3 edge case tests = 10 total
- **Coverage:** All 4 requirements from ASSUMPTIONS_AND_TESTING.md
- **Code Lines:** ~800 lines (including comments and documentation)
- **Helper Functions:** 4 main helpers + 2 classes
- **Test Duration:** ~10-15 minutes for full suite
- **Assertions:** ~40+ assertions across all tests

## Integration with Post-Edit Hook

The test file was validated with the post-edit pipeline:
```bash
node config/hooks/post-edit-pipeline.js tests/parallelization/chaos.test.ts \
  --memory-key "tester/chaos-tests" --structured
```

**Validation Results:**
- âœ… TypeScript syntax valid
- âœ… Import paths correct
- âœ… Uses ioredis (matching existing tests)
- âŒ Vitest dependency missing (expected - needs installation)

## Confidence Score: 0.85

**Reasoning:**
- âœ… All 4 requirements implemented with comprehensive tests
- âœ… Follows existing test patterns (orphan-detection.test.ts, redis-pubsub.test.ts)
- âœ… Uses consistent Redis configuration and helper utilities
- âœ… Proper TypeScript types and interfaces
- âœ… Comprehensive edge case coverage
- âœ… Detailed console logging for debugging
- âŒ Vitest dependency missing (blocker for execution)
- âŒ Cannot execute tests until vitest installed

**Blocker:** Single dependency installation required before test execution

## Recommendations

1. **Install Vitest:**
   ```bash
   npm install --save-dev vitest
   ```

2. **Add to package.json scripts:**
   ```json
   {
     "scripts": {
       "test:parallelization": "vitest run tests/parallelization --timeout 20m"
     }
   }
   ```

3. **Execute tests:**
   ```bash
   npm run test:parallelization
   ```

4. **Monitor metrics:**
   - Watch cleanup rates (should be 100%)
   - Track recovery times (should be <30s)
   - Verify conflict detection (should be 100%)
   - Validate lock expiration (should expire within TTL)

## Next Steps

1. Install vitest dependency
2. Run tests to validate all scenarios
3. Integrate with CI/CD pipeline
4. Monitor chaos test results in production environment
5. Add additional edge cases as needed based on real-world failures

---

**Epic:** parallel-cfn-loop
**Sprint:** Chaos Engineering Validation
**Status:** Implementation Complete - Pending Dependency Installation
**Confidence:** 0.85
