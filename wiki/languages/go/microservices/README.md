# Go Microservices Architecture with Claude-Flow

Build scalable, distributed microservices using Go and claude-flow-novice for automated development, testing, and deployment.

## üèóÔ∏è Microservices Architecture Overview

### Quick Microservice Generation
```bash
# Generate complete microservice with claude-flow
npx claude-flow-novice sparc pipeline "Go microservice with gRPC, REST API, and database"

# Or use MCP for complex coordination
npx claude-flow-novice mcp swarm_init --topology mesh --max-agents 6
npx claude-flow-novice mcp agent_spawn --type backend-dev --capabilities microservices,grpc,kubernetes
```

## üåê Service Communication Patterns

### gRPC Service Implementation
```bash
# Generate gRPC microservice with claude-flow
npx claude-flow-novice sparc run architect "gRPC microservice with Protocol Buffers and middleware"
```

**Generated gRPC Service:**
```go
// api/proto/user_service.proto - Generated by claude-flow
syntax = "proto3";

package userservice;

option go_package = "github.com/username/user-service/api/proto";

import "google/protobuf/timestamp.proto";
import "google/protobuf/empty.proto";

service UserService {
  rpc CreateUser(CreateUserRequest) returns (User);
  rpc GetUser(GetUserRequest) returns (User);
  rpc UpdateUser(UpdateUserRequest) returns (User);
  rpc DeleteUser(DeleteUserRequest) returns (google.protobuf.Empty);
  rpc ListUsers(ListUsersRequest) returns (ListUsersResponse);
  rpc GetUserByEmail(GetUserByEmailRequest) returns (User);
}

message User {
  int64 id = 1;
  string name = 2;
  string email = 3;
  google.protobuf.Timestamp created_at = 4;
  google.protobuf.Timestamp updated_at = 5;
}

message CreateUserRequest {
  string name = 1;
  string email = 2;
}

message GetUserRequest {
  int64 id = 1;
}

message UpdateUserRequest {
  int64 id = 1;
  string name = 2;
  string email = 3;
}

message DeleteUserRequest {
  int64 id = 1;
}

message ListUsersRequest {
  int32 page_size = 1;
  string page_token = 2;
}

message ListUsersResponse {
  repeated User users = 1;
  string next_page_token = 2;
  int32 total_count = 3;
}

message GetUserByEmailRequest {
  string email = 1;
}
```

**Generated gRPC Server:**
```go
// internal/grpc/server.go - Generated by claude-flow
package grpc

import (
    "context"
    "fmt"
    "net"
    "time"

    "google.golang.org/grpc"
    "google.golang.org/grpc/health"
    "google.golang.org/grpc/health/grpc_health_v1"
    "google.golang.org/grpc/keepalive"
    "google.golang.org/grpc/reflection"
    "go.uber.org/zap"

    pb "github.com/username/user-service/api/proto"
    "github.com/username/user-service/internal/middleware"
    "github.com/username/user-service/internal/services"
)

type Server struct {
    logger      *zap.Logger
    userService *services.UserService
    grpcServer  *grpc.Server
    listener    net.Listener
}

func NewServer(logger *zap.Logger, userService *services.UserService) *Server {
    return &Server{
        logger:      logger,
        userService: userService,
    }
}

func (s *Server) Start(port int) error {
    listener, err := net.Listen("tcp", fmt.Sprintf(":%d", port))
    if err != nil {
        return fmt.Errorf("failed to listen on port %d: %w", port, err)
    }

    s.listener = listener

    // gRPC server options
    opts := []grpc.ServerOption{
        grpc.KeepaliveParams(keepalive.ServerParameters{
            MaxConnectionIdle:     15 * time.Second,
            MaxConnectionAge:      30 * time.Second,
            MaxConnectionAgeGrace: 5 * time.Second,
            Time:                  5 * time.Second,
            Timeout:               1 * time.Second,
        }),
        grpc.KeepaliveEnforcementPolicy(keepalive.EnforcementPolicy{
            MinTime:             5 * time.Second,
            PermitWithoutStream: true,
        }),
        grpc.UnaryInterceptor(middleware.ChainUnaryInterceptors(
            middleware.LoggingInterceptor(s.logger),
            middleware.AuthInterceptor(),
            middleware.RateLimitInterceptor(),
            middleware.ValidationInterceptor(),
            middleware.MetricsInterceptor(),
        )),
        grpc.StreamInterceptor(middleware.ChainStreamInterceptors(
            middleware.StreamLoggingInterceptor(s.logger),
            middleware.StreamAuthInterceptor(),
        )),
    }

    s.grpcServer = grpc.NewServer(opts...)

    // Register services
    pb.RegisterUserServiceServer(s.grpcServer, s)

    // Register health check
    healthServer := health.NewServer()
    grpc_health_v1.RegisterHealthServer(s.grpcServer, healthServer)
    healthServer.SetServingStatus("user-service", grpc_health_v1.HealthCheckResponse_SERVING)

    // Enable reflection for development
    reflection.Register(s.grpcServer)

    s.logger.Info("Starting gRPC server", zap.Int("port", port))

    return s.grpcServer.Serve(listener)
}

func (s *Server) Stop() {
    if s.grpcServer != nil {
        s.grpcServer.GracefulStop()
    }
}

// gRPC service implementations
func (s *Server) CreateUser(ctx context.Context, req *pb.CreateUserRequest) (*pb.User, error) {
    user, err := s.userService.CreateUser(ctx, &services.CreateUserParams{
        Name:  req.Name,
        Email: req.Email,
    })
    if err != nil {
        s.logger.Error("Failed to create user", zap.Error(err))
        return nil, err
    }

    return &pb.User{
        Id:        user.ID,
        Name:      user.Name,
        Email:     user.Email,
        CreatedAt: timestamppb.New(user.CreatedAt),
        UpdatedAt: timestamppb.New(user.UpdatedAt),
    }, nil
}

func (s *Server) GetUser(ctx context.Context, req *pb.GetUserRequest) (*pb.User, error) {
    user, err := s.userService.GetUser(ctx, req.Id)
    if err != nil {
        s.logger.Error("Failed to get user", zap.Int64("id", req.Id), zap.Error(err))
        return nil, err
    }

    return &pb.User{
        Id:        user.ID,
        Name:      user.Name,
        Email:     user.Email,
        CreatedAt: timestamppb.New(user.CreatedAt),
        UpdatedAt: timestamppb.New(user.UpdatedAt),
    }, nil
}

func (s *Server) UpdateUser(ctx context.Context, req *pb.UpdateUserRequest) (*pb.User, error) {
    user, err := s.userService.UpdateUser(ctx, &services.UpdateUserParams{
        ID:    req.Id,
        Name:  req.Name,
        Email: req.Email,
    })
    if err != nil {
        s.logger.Error("Failed to update user", zap.Int64("id", req.Id), zap.Error(err))
        return nil, err
    }

    return &pb.User{
        Id:        user.ID,
        Name:      user.Name,
        Email:     user.Email,
        CreatedAt: timestamppb.New(user.CreatedAt),
        UpdatedAt: timestamppb.New(user.UpdatedAt),
    }, nil
}

func (s *Server) DeleteUser(ctx context.Context, req *pb.DeleteUserRequest) (*emptypb.Empty, error) {
    err := s.userService.DeleteUser(ctx, req.Id)
    if err != nil {
        s.logger.Error("Failed to delete user", zap.Int64("id", req.Id), zap.Error(err))
        return nil, err
    }

    return &emptypb.Empty{}, nil
}

func (s *Server) ListUsers(ctx context.Context, req *pb.ListUsersRequest) (*pb.ListUsersResponse, error) {
    users, nextToken, totalCount, err := s.userService.ListUsers(ctx, &services.ListUsersParams{
        PageSize:  int(req.PageSize),
        PageToken: req.PageToken,
    })
    if err != nil {
        s.logger.Error("Failed to list users", zap.Error(err))
        return nil, err
    }

    pbUsers := make([]*pb.User, len(users))
    for i, user := range users {
        pbUsers[i] = &pb.User{
            Id:        user.ID,
            Name:      user.Name,
            Email:     user.Email,
            CreatedAt: timestamppb.New(user.CreatedAt),
            UpdatedAt: timestamppb.New(user.UpdatedAt),
        }
    }

    return &pb.ListUsersResponse{
        Users:         pbUsers,
        NextPageToken: nextToken,
        TotalCount:    int32(totalCount),
    }, nil
}

func (s *Server) GetUserByEmail(ctx context.Context, req *pb.GetUserByEmailRequest) (*pb.User, error) {
    user, err := s.userService.GetUserByEmail(ctx, req.Email)
    if err != nil {
        s.logger.Error("Failed to get user by email", zap.String("email", req.Email), zap.Error(err))
        return nil, err
    }

    return &pb.User{
        Id:        user.ID,
        Name:      user.Name,
        Email:     user.Email,
        CreatedAt: timestamppb.New(user.CreatedAt),
        UpdatedAt: timestamppb.New(user.UpdatedAt),
    }, nil
}
```

### REST Gateway Integration
```go
// internal/gateway/gateway.go - Generated by claude-flow
package gateway

import (
    "context"
    "fmt"
    "net/http"

    "github.com/grpc-ecosystem/grpc-gateway/v2/runtime"
    "google.golang.org/grpc"
    "google.golang.org/grpc/credentials/insecure"
    "go.uber.org/zap"

    pb "github.com/username/user-service/api/proto"
)

type Gateway struct {
    logger     *zap.Logger
    grpcAddr   string
    httpServer *http.Server
}

func NewGateway(logger *zap.Logger, grpcAddr string) *Gateway {
    return &Gateway{
        logger:   logger,
        grpcAddr: grpcAddr,
    }
}

func (g *Gateway) Start(port int) error {
    ctx := context.Background()

    // Create gRPC connection
    conn, err := grpc.DialContext(
        ctx,
        g.grpcAddr,
        grpc.WithTransportCredentials(insecure.NewCredentials()),
        grpc.WithBlock(),
    )
    if err != nil {
        return fmt.Errorf("failed to connect to gRPC server: %w", err)
    }

    // Create gateway mux
    mux := runtime.NewServeMux(
        runtime.WithIncomingHeaderMatcher(func(key string) (string, bool) {
            switch key {
            case "Authorization", "X-Request-Id", "X-User-Id":
                return key, true
            default:
                return "", false
            }
        }),
        runtime.WithErrorHandler(g.errorHandler),
    )

    // Register gRPC-Gateway handlers
    if err := pb.RegisterUserServiceHandler(ctx, mux, conn); err != nil {
        return fmt.Errorf("failed to register gateway: %w", err)
    }

    // Add middleware
    handler := g.corsMiddleware(g.loggingMiddleware(mux))

    g.httpServer = &http.Server{
        Addr:    fmt.Sprintf(":%d", port),
        Handler: handler,
    }

    g.logger.Info("Starting HTTP gateway", zap.Int("port", port))

    return g.httpServer.ListenAndServe()
}

func (g *Gateway) Stop(ctx context.Context) error {
    if g.httpServer != nil {
        return g.httpServer.Shutdown(ctx)
    }
    return nil
}

func (g *Gateway) corsMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        w.Header().Set("Access-Control-Allow-Origin", "*")
        w.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
        w.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization, X-Request-Id")

        if r.Method == "OPTIONS" {
            w.WriteHeader(http.StatusOK)
            return
        }

        next.ServeHTTP(w, r)
    })
}

func (g *Gateway) loggingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        next.ServeHTTP(w, r)

        g.logger.Info("HTTP request",
            zap.String("method", r.Method),
            zap.String("path", r.URL.Path),
            zap.Duration("duration", time.Since(start)),
        )
    })
}

func (g *Gateway) errorHandler(ctx context.Context, mux *runtime.ServeMux, marshaler runtime.Marshaler, w http.ResponseWriter, r *http.Request, err error) {
    // Custom error handling
    g.logger.Error("Gateway error", zap.Error(err))
    runtime.DefaultHTTPErrorHandler(ctx, mux, marshaler, w, r, err)
}
```

## üîÑ Service Discovery and Communication

### Service Registry Implementation
```go
// internal/discovery/registry.go - Generated by claude-flow
package discovery

import (
    "context"
    "fmt"
    "sync"
    "time"

    "go.etcd.io/etcd/clientv3"
    "go.uber.org/zap"
)

type ServiceRegistry struct {
    client    *clientv3.Client
    logger    *zap.Logger
    services  sync.Map
    leaseID   clientv3.LeaseID
    keepAlive <-chan *clientv3.LeaseKeepAliveResponse
}

type ServiceInfo struct {
    Name     string `json:"name"`
    Address  string `json:"address"`
    Port     int    `json:"port"`
    Health   string `json:"health"`
    Metadata map[string]string `json:"metadata"`
}

func NewServiceRegistry(endpoints []string, logger *zap.Logger) (*ServiceRegistry, error) {
    client, err := clientv3.New(clientv3.Config{
        Endpoints:   endpoints,
        DialTimeout: 5 * time.Second,
    })
    if err != nil {
        return nil, fmt.Errorf("failed to create etcd client: %w", err)
    }

    return &ServiceRegistry{
        client: client,
        logger: logger,
    }, nil
}

func (sr *ServiceRegistry) Register(ctx context.Context, service *ServiceInfo) error {
    // Create lease
    lease, err := sr.client.Grant(ctx, 30) // 30 second TTL
    if err != nil {
        return fmt.Errorf("failed to create lease: %w", err)
    }

    sr.leaseID = lease.ID

    // Register service
    key := fmt.Sprintf("/services/%s/%s:%d", service.Name, service.Address, service.Port)
    value, err := json.Marshal(service)
    if err != nil {
        return fmt.Errorf("failed to marshal service info: %w", err)
    }

    _, err = sr.client.Put(ctx, key, string(value), clientv3.WithLease(lease.ID))
    if err != nil {
        return fmt.Errorf("failed to register service: %w", err)
    }

    // Keep lease alive
    sr.keepAlive, err = sr.client.KeepAlive(ctx, lease.ID)
    if err != nil {
        return fmt.Errorf("failed to keep lease alive: %w", err)
    }

    // Handle keep alive responses
    go sr.handleKeepAlive()

    sr.logger.Info("Service registered",
        zap.String("service", service.Name),
        zap.String("address", service.Address),
        zap.Int("port", service.Port),
    )

    return nil
}

func (sr *ServiceRegistry) Deregister(ctx context.Context, service *ServiceInfo) error {
    key := fmt.Sprintf("/services/%s/%s:%d", service.Name, service.Address, service.Port)

    _, err := sr.client.Delete(ctx, key)
    if err != nil {
        return fmt.Errorf("failed to deregister service: %w", err)
    }

    // Revoke lease
    if sr.leaseID != 0 {
        _, err = sr.client.Revoke(ctx, sr.leaseID)
        if err != nil {
            sr.logger.Warn("Failed to revoke lease", zap.Error(err))
        }
    }

    sr.logger.Info("Service deregistered",
        zap.String("service", service.Name),
        zap.String("address", service.Address),
        zap.Int("port", service.Port),
    )

    return nil
}

func (sr *ServiceRegistry) Discover(ctx context.Context, serviceName string) ([]*ServiceInfo, error) {
    key := fmt.Sprintf("/services/%s/", serviceName)

    resp, err := sr.client.Get(ctx, key, clientv3.WithPrefix())
    if err != nil {
        return nil, fmt.Errorf("failed to discover services: %w", err)
    }

    var services []*ServiceInfo
    for _, kv := range resp.Kvs {
        var service ServiceInfo
        if err := json.Unmarshal(kv.Value, &service); err != nil {
            sr.logger.Warn("Failed to unmarshal service info", zap.Error(err))
            continue
        }
        services = append(services, &service)
    }

    return services, nil
}

func (sr *ServiceRegistry) Watch(ctx context.Context, serviceName string, callback func([]*ServiceInfo)) {
    key := fmt.Sprintf("/services/%s/", serviceName)

    watchChan := sr.client.Watch(ctx, key, clientv3.WithPrefix())

    go func() {
        for watchResp := range watchChan {
            if watchResp.Err() != nil {
                sr.logger.Error("Watch error", zap.Error(watchResp.Err()))
                continue
            }

            // Get current services
            services, err := sr.Discover(ctx, serviceName)
            if err != nil {
                sr.logger.Error("Failed to discover services during watch", zap.Error(err))
                continue
            }

            callback(services)
        }
    }()
}

func (sr *ServiceRegistry) handleKeepAlive() {
    for ka := range sr.keepAlive {
        if ka == nil {
            sr.logger.Error("Keep alive channel closed")
            break
        }
        sr.logger.Debug("Lease renewed", zap.Int64("lease_id", int64(sr.leaseID)))
    }
}

func (sr *ServiceRegistry) Close() error {
    return sr.client.Close()
}
```

### Load Balancer
```go
// internal/loadbalancer/balancer.go - Generated by claude-flow
package loadbalancer

import (
    "context"
    "errors"
    "math/rand"
    "sync"
    "sync/atomic"
    "time"

    "github.com/username/user-service/internal/discovery"
)

type LoadBalancer interface {
    Next() (*discovery.ServiceInfo, error)
    UpdateServices([]*discovery.ServiceInfo)
}

// Round Robin Load Balancer
type RoundRobinBalancer struct {
    services []*discovery.ServiceInfo
    index    uint64
    mutex    sync.RWMutex
}

func NewRoundRobinBalancer() *RoundRobinBalancer {
    return &RoundRobinBalancer{}
}

func (rb *RoundRobinBalancer) Next() (*discovery.ServiceInfo, error) {
    rb.mutex.RLock()
    defer rb.mutex.RUnlock()

    if len(rb.services) == 0 {
        return nil, errors.New("no services available")
    }

    index := atomic.AddUint64(&rb.index, 1) % uint64(len(rb.services))
    return rb.services[index], nil
}

func (rb *RoundRobinBalancer) UpdateServices(services []*discovery.ServiceInfo) {
    rb.mutex.Lock()
    defer rb.mutex.Unlock()

    rb.services = make([]*discovery.ServiceInfo, len(services))
    copy(rb.services, services)
}

// Weighted Random Load Balancer
type WeightedRandomBalancer struct {
    services        []*discovery.ServiceInfo
    weights         []int
    totalWeight     int
    mutex           sync.RWMutex
    healthChecker   *HealthChecker
}

func NewWeightedRandomBalancer(healthChecker *HealthChecker) *WeightedRandomBalancer {
    return &WeightedRandomBalancer{
        healthChecker: healthChecker,
    }
}

func (wrb *WeightedRandomBalancer) Next() (*discovery.ServiceInfo, error) {
    wrb.mutex.RLock()
    defer wrb.mutex.RUnlock()

    if len(wrb.services) == 0 {
        return nil, errors.New("no services available")
    }

    if wrb.totalWeight == 0 {
        // Fallback to random selection
        index := rand.Intn(len(wrb.services))
        return wrb.services[index], nil
    }

    // Weighted random selection
    target := rand.Intn(wrb.totalWeight)
    current := 0

    for i, weight := range wrb.weights {
        current += weight
        if current > target {
            return wrb.services[i], nil
        }
    }

    // Fallback
    return wrb.services[0], nil
}

func (wrb *WeightedRandomBalancer) UpdateServices(services []*discovery.ServiceInfo) {
    wrb.mutex.Lock()
    defer wrb.mutex.Unlock()

    wrb.services = make([]*discovery.ServiceInfo, 0, len(services))
    wrb.weights = make([]int, 0, len(services))
    wrb.totalWeight = 0

    for _, service := range services {
        if wrb.healthChecker.IsHealthy(service) {
            weight := wrb.calculateWeight(service)
            wrb.services = append(wrb.services, service)
            wrb.weights = append(wrb.weights, weight)
            wrb.totalWeight += weight
        }
    }
}

func (wrb *WeightedRandomBalancer) calculateWeight(service *discovery.ServiceInfo) int {
    // Base weight
    weight := 100

    // Adjust based on health metrics (if available)
    if latency, ok := wrb.healthChecker.GetLatency(service); ok {
        if latency < 10*time.Millisecond {
            weight += 50
        } else if latency > 100*time.Millisecond {
            weight -= 30
        }
    }

    if weight < 1 {
        weight = 1
    }

    return weight
}

// Health Checker
type HealthChecker struct {
    healthStatus sync.Map // service address -> health status
    latencies    sync.Map // service address -> latency
}

func NewHealthChecker() *HealthChecker {
    return &HealthChecker{}
}

func (hc *HealthChecker) IsHealthy(service *discovery.ServiceInfo) bool {
    if status, ok := hc.healthStatus.Load(service.Address); ok {
        return status.(bool)
    }
    return true // Default to healthy
}

func (hc *HealthChecker) GetLatency(service *discovery.ServiceInfo) (time.Duration, bool) {
    if latency, ok := hc.latencies.Load(service.Address); ok {
        return latency.(time.Duration), true
    }
    return 0, false
}

func (hc *HealthChecker) UpdateHealth(service *discovery.ServiceInfo, healthy bool) {
    hc.healthStatus.Store(service.Address, healthy)
}

func (hc *HealthChecker) UpdateLatency(service *discovery.ServiceInfo, latency time.Duration) {
    hc.latencies.Store(service.Address, latency)
}

func (hc *HealthChecker) StartHealthChecks(ctx context.Context, services []*discovery.ServiceInfo) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            for _, service := range services {
                go hc.checkHealth(ctx, service)
            }
        case <-ctx.Done():
            return
        }
    }
}

func (hc *HealthChecker) checkHealth(ctx context.Context, service *discovery.ServiceInfo) {
    start := time.Now()

    // Perform health check (implement based on your service)
    // This is a simple TCP connection check
    addr := fmt.Sprintf("%s:%d", service.Address, service.Port)
    conn, err := net.DialTimeout("tcp", addr, 5*time.Second)

    latency := time.Since(start)
    hc.UpdateLatency(service, latency)

    if err != nil {
        hc.UpdateHealth(service, false)
        return
    }

    conn.Close()
    hc.UpdateHealth(service, true)
}
```

## üóÑÔ∏è Data Management Patterns

### Database per Service Pattern
```bash
# Generate database integration with claude-flow
npx claude-flow-novice sparc run architect "database per service pattern with PostgreSQL and Redis"
```

### Event Sourcing and CQRS
```go
// internal/events/event_store.go - Generated by claude-flow
package events

import (
    "context"
    "encoding/json"
    "fmt"
    "time"

    "github.com/google/uuid"
    "gorm.io/gorm"
)

type Event struct {
    ID            string    `json:"id" gorm:"primaryKey"`
    AggregateID   string    `json:"aggregate_id" gorm:"index"`
    AggregateType string    `json:"aggregate_type"`
    EventType     string    `json:"event_type"`
    EventData     string    `json:"event_data"`
    Version       int       `json:"version"`
    Timestamp     time.Time `json:"timestamp"`
}

type EventStore interface {
    SaveEvents(ctx context.Context, aggregateID string, events []Event, expectedVersion int) error
    GetEvents(ctx context.Context, aggregateID string) ([]Event, error)
    GetEventsFromVersion(ctx context.Context, aggregateID string, version int) ([]Event, error)
    GetAllEvents(ctx context.Context, offset, limit int) ([]Event, error)
}

type PostgreSQLEventStore struct {
    db *gorm.DB
}

func NewPostgreSQLEventStore(db *gorm.DB) *PostgreSQLEventStore {
    return &PostgreSQLEventStore{db: db}
}

func (es *PostgreSQLEventStore) SaveEvents(ctx context.Context, aggregateID string, events []Event, expectedVersion int) error {
    return es.db.WithContext(ctx).Transaction(func(tx *gorm.DB) error {
        // Check current version
        var currentVersion int
        if err := tx.Model(&Event{}).
            Where("aggregate_id = ?", aggregateID).
            Select("COALESCE(MAX(version), 0)").
            Scan(&currentVersion).Error; err != nil {
            return fmt.Errorf("failed to get current version: %w", err)
        }

        if currentVersion != expectedVersion {
            return fmt.Errorf("concurrency conflict: expected version %d, got %d", expectedVersion, currentVersion)
        }

        // Save events
        for i, event := range events {
            event.ID = uuid.New().String()
            event.AggregateID = aggregateID
            event.Version = expectedVersion + i + 1
            event.Timestamp = time.Now()

            if err := tx.Create(&event).Error; err != nil {
                return fmt.Errorf("failed to save event: %w", err)
            }
        }

        return nil
    })
}

func (es *PostgreSQLEventStore) GetEvents(ctx context.Context, aggregateID string) ([]Event, error) {
    var events []Event
    if err := es.db.WithContext(ctx).
        Where("aggregate_id = ?", aggregateID).
        Order("version ASC").
        Find(&events).Error; err != nil {
        return nil, fmt.Errorf("failed to get events: %w", err)
    }
    return events, nil
}

func (es *PostgreSQLEventStore) GetEventsFromVersion(ctx context.Context, aggregateID string, version int) ([]Event, error) {
    var events []Event
    if err := es.db.WithContext(ctx).
        Where("aggregate_id = ? AND version > ?", aggregateID, version).
        Order("version ASC").
        Find(&events).Error; err != nil {
        return nil, fmt.Errorf("failed to get events from version: %w", err)
    }
    return events, nil
}

func (es *PostgreSQLEventStore) GetAllEvents(ctx context.Context, offset, limit int) ([]Event, error) {
    var events []Event
    if err := es.db.WithContext(ctx).
        Order("timestamp ASC").
        Offset(offset).
        Limit(limit).
        Find(&events).Error; err != nil {
        return nil, fmt.Errorf("failed to get all events: %w", err)
    }
    return events, nil
}

// Event Bus for publishing events
type EventBus interface {
    Publish(ctx context.Context, event Event) error
    Subscribe(eventType string, handler EventHandler)
}

type EventHandler func(ctx context.Context, event Event) error

type InMemoryEventBus struct {
    handlers map[string][]EventHandler
    mutex    sync.RWMutex
}

func NewInMemoryEventBus() *InMemoryEventBus {
    return &InMemoryEventBus{
        handlers: make(map[string][]EventHandler),
    }
}

func (bus *InMemoryEventBus) Publish(ctx context.Context, event Event) error {
    bus.mutex.RLock()
    handlers := bus.handlers[event.EventType]
    bus.mutex.RUnlock()

    for _, handler := range handlers {
        if err := handler(ctx, event); err != nil {
            return fmt.Errorf("handler failed for event %s: %w", event.EventType, err)
        }
    }

    return nil
}

func (bus *InMemoryEventBus) Subscribe(eventType string, handler EventHandler) {
    bus.mutex.Lock()
    defer bus.mutex.Unlock()

    bus.handlers[eventType] = append(bus.handlers[eventType], handler)
}

// Aggregate base for event sourcing
type Aggregate struct {
    ID      string
    Version int
    changes []Event
}

func (a *Aggregate) AddEvent(eventType string, eventData interface{}) error {
    data, err := json.Marshal(eventData)
    if err != nil {
        return fmt.Errorf("failed to marshal event data: %w", err)
    }

    event := Event{
        EventType: eventType,
        EventData: string(data),
    }

    a.changes = append(a.changes, event)
    return nil
}

func (a *Aggregate) GetChanges() []Event {
    return a.changes
}

func (a *Aggregate) ClearChanges() {
    a.changes = nil
}
```

## üê≥ Containerization and Deployment

### Multi-stage Docker Build
```dockerfile
# Dockerfile - Generated by claude-flow
# Build stage
FROM golang:1.21-alpine AS builder

WORKDIR /app

# Install dependencies
RUN apk add --no-cache git ca-certificates tzdata

# Copy go mod files
COPY go.mod go.sum ./

# Download dependencies
RUN go mod download

# Copy source code
COPY . .

# Build the application
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo \
    -ldflags="-w -s" \
    -o main ./cmd/server

# Final stage
FROM scratch

# Import from builder
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
COPY --from=builder /usr/share/zoneinfo /usr/share/zoneinfo
COPY --from=builder /app/main /app/main

# Create non-root user
USER 1000

EXPOSE 8080 9090

ENTRYPOINT ["/app/main"]
```

### Kubernetes Deployment
```yaml
# deployments/k8s/deployment.yaml - Generated by claude-flow
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  labels:
    app: user-service
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
      version: v1
  template:
    metadata:
      labels:
        app: user-service
        version: v1
    spec:
      containers:
      - name: user-service
        image: user-service:latest
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: grpc
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: user-service-secrets
              key: database-url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: user-service-secrets
              key: redis-url
        resources:
          requests:
            memory: "64Mi"
            cpu: "250m"
          limits:
            memory: "128Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: user-service-config
---
apiVersion: v1
kind: Service
metadata:
  name: user-service
  labels:
    app: user-service
spec:
  selector:
    app: user-service
  ports:
  - name: http
    port: 80
    targetPort: 8080
  - name: grpc
    port: 9090
    targetPort: 9090
  type: ClusterIP
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: user-service-config
data:
  config.yaml: |
    server:
      port: 8080
      grpc_port: 9090
    database:
      max_connections: 25
      max_idle_connections: 5
    redis:
      pool_size: 10
    logging:
      level: info
      format: json
```

## üöÄ Claude-Flow Microservices Commands

```bash
# Generate complete microservice
npx claude-flow-novice sparc pipeline "Go microservice with gRPC, REST, database, and Kubernetes deployment"

# Add specific features
npx claude-flow-novice sparc run architect "add event sourcing and CQRS to microservice"
npx claude-flow-novice sparc run coder "implement service discovery with etcd"
npx claude-flow-novice sparc run coder "add distributed tracing with Jaeger"

# Testing microservices
npx claude-flow-novice sparc run tester "create integration tests for microservice"
npx claude-flow-novice sparc run tester "add contract testing with Pact"

# Deployment and operations
npx claude-flow-novice sparc run deployer "deploy microservice to Kubernetes with Helm"
npx claude-flow-novice sparc run coder "add monitoring and alerting with Prometheus"
```

## üìä Observability and Monitoring

### Distributed Tracing
```bash
# Add tracing with claude-flow
npx claude-flow-novice sparc run coder "add OpenTelemetry distributed tracing"
```

### Metrics and Health Checks
```bash
# Add comprehensive monitoring
npx claude-flow-novice sparc run coder "add Prometheus metrics and health checks"
```

## üõ°Ô∏è Best Practices

### 1. Service Design
- **Single Responsibility**: Each service owns a specific business capability
- **Database per Service**: Avoid shared databases
- **API Versioning**: Use semantic versioning for APIs
- **Circuit Breakers**: Implement fault tolerance patterns

### 2. Communication
- **Async First**: Prefer asynchronous communication
- **Event-Driven**: Use events for loose coupling
- **Idempotency**: Make operations idempotent
- **Timeouts**: Set appropriate timeouts for all calls

### 3. Data Management
- **Eventual Consistency**: Design for eventual consistency
- **Saga Pattern**: Handle distributed transactions
- **Event Sourcing**: Consider for audit requirements
- **CQRS**: Separate read and write models when needed

### 4. Operations
- **Containerization**: Use Docker for consistent deployments
- **Service Mesh**: Consider Istio for advanced traffic management
- **Monitoring**: Comprehensive logging, metrics, and tracing
- **Security**: Implement authentication and authorization

**Next Steps:**
- [Integration](../integration/) - Advanced claude-flow-novice integration patterns
- [Examples](../examples/) - Complete microservice implementations
- [Performance](../performance/) - Optimize microservice performance