# 8-Hour Stability Test Configuration
# Phase 2 Sprint 2.3 - 50 Agent Continuous Load Test
# Success Criteria: <5% memory growth, >1000 msg/s, no resource leaks

version: '3.8'

services:
  # Main stability test runner
  stability-test:
    build:
      context: ../..
      dockerfile: Dockerfile
      args:
        - NODE_ENV=production
        - APP_VERSION=1.6.6
    image: claude-flow-novice:stability-test
    container_name: cfn-stability-test
    restart: "no"
    environment:
      - NODE_ENV=production
      - CFN_MAX_AGENTS=50
      - TEST_DURATION_HOURS=8
      - MESSAGE_THROUGHPUT_TARGET=1000
      - MEMORY_GROWTH_THRESHOLD=0.05
      - ENABLE_METRICS=true
      - METRICS_INTERVAL=10
      - LOG_LEVEL=info
    volumes:
      - stability-results:/app/stability-results
      - ../../scripts/monitoring:/app/monitoring:ro
      - ../../tests:/app/tests:ro
    networks:
      - stability-network
    command: >
      sh -c "
        echo 'Starting 8-hour stability test with 50 agents...' &&
        mkdir -p /app/stability-results &&
        node .claude-flow-novice/dist/src/cli/main.js swarm init --max-agents 50 --topology mesh --strategy balanced &&
        /app/monitoring/resource-monitor.sh /app/stability-results &
        MONITOR_PID=\$! &&
        echo \"Resource monitor started (PID: \$MONITOR_PID)\" &&
        node .claude-flow-novice/dist/src/cli/main.js test stability --duration 28800 --agents 50 --throughput 1000 &&
        kill \$MONITOR_PID &&
        echo 'Stability test complete. Generating report...' &&
        node /app/tests/performance/analyze-stability-results.js /app/stability-results
      "
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
      nproc:
        soft: 4096
        hard: 4096
    mem_limit: 8g
    mem_reservation: 4g
    cpus: 4
    healthcheck:
      test: ["CMD", "pgrep", "-f", "node"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Monitoring stack
  prometheus:
    image: prom/prometheus:latest
    container_name: cfn-stability-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.stability.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-stability-data:/prometheus
    networks:
      - stability-network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=12h'
      - '--web.enable-lifecycle'
    mem_limit: 2g
    cpus: 2

  # Grafana for real-time visualization
  grafana:
    image: grafana/grafana:latest
    container_name: cfn-stability-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=stability-test
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
    volumes:
      - grafana-stability-data:/var/lib/grafana
      - ./grafana-dashboards:/etc/grafana/provisioning/dashboards:ro
    networks:
      - stability-network
    depends_on:
      - prometheus
    mem_limit: 1g
    cpus: 1

  # Node exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: cfn-stability-node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    networks:
      - stability-network
    command:
      - '--path.rootfs=/host'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /:/host:ro,rslave
    mem_limit: 256m
    cpus: 0.5

networks:
  stability-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16

volumes:
  stability-results:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./stability-results
  prometheus-stability-data:
    driver: local
  grafana-stability-data:
    driver: local
